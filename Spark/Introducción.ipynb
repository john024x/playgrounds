{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyNgqBfc4sm6Ok2GooZhR9t+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"NAqf6Fw-61Rx"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["#Spark\n","##Caracteristicas\n","\n","*  Framework de desarrollo de procesos de Big Data\n","*  Framework proocupado por la velocidad del proceso\n","* Se enfoca en el procesamiento desde la RAM\n","* Posee módulo para grafos, streaming y ML.\n","* No depende de un sistema de archivos\n","\n","Se puede utilizar con Java, Scala (Nativo), Python y R\n","\n","---\n","##Que no es Apache Spark\n","\n","\n","*   Una base de datos\n","\n","\n","Nace en 2009, en la Universidad de Berkeley <br>\n","Heredero de Hadoop"],"metadata":{"id":"MZ_Kvy4D65_t"}},{"cell_type":"markdown","source":["#Caracteristicas de los RDD\n","* Principal abstraccion de datos\n","* Distribución \n","1.   **Creación** simple (Sin estrucutra formal)\n","2.   **Inmutabilidad** \n","\n","Es de ejecución perezosa, no corre a menos que se realice una acción\n","##Cuando usar un RDD\n","* Cuando te interese controlar el flujo de Spark\n","* Desde Python, se pueden convertir los RDD a un conjunto de datos desde Python\n","* Compatible con versiones antiguas de Spark"],"metadata":{"id":"k3Paon5yBeuO"}},{"cell_type":"markdown","source":["#Caracteristicas de un DataFrame\n","* Fromato: Poseen estructura\n","* Optimización: Poseen una mejor implementación, siendo mas rápidos\n","* De **fácil** creación\n","##Cuando usar Dataframes\n","* Si poseemos semánticas de datos complicadas\n","* Tareas de alto nivel, filtro, mapeos, agregaciones, promedios, sumas\n","* Si vamos a usar sentencias SQL-like"],"metadata":{"id":"7DxOWb-ICbD9"}}]}